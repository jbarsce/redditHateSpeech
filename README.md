Caracterizaci√≥n de discurso de odio en r/argentina


---

√çndice

- [Vistazo r√°pido](#vistazo-r√°pido)
  - [Instalaci√≥n](#instalaci√≥n)
    - [Instalaci√≥n con conda](#instalaci√≥n-con-conda)
    - [Instalaci√≥n con Docker Compose](#instalaci√≥n-con-docker-compose)
  - [Flujo de datos generados](#flujo-de-datos-generados)
- [Informe del proyecto](#informe-del-proyecto)
  - [Introducci√≥n](#introducci√≥n)
    - [Motivaci√≥n](#motivaci√≥n)
    - [Discurso de odio](#discurso-de-odio)
    - [r/argentina](#rargentina)
      - [¬øPor qu√© r/argentina?](#por-qu√©-rargentina)
      - [Estructura general de un post](#estructura-general-de-un-post)
  - [1. Obtenci√≥n de datos](#1-obtenci√≥n-de-datos)
  - [2. Pre-procesamiento](#2-pre-procesamiento)
  - [3. Embeddings](#3-embeddings)
    - [3a. Embeddings con LDA](#3a-embeddings-con-lda)
    - [3b. Embeddings con Word2Vec](#3b-embeddings-con-word2vec)
    - [3c. Embeddings con FastText](#3c-embeddings-con-fasttext)
  - [4. Entrenamiento de detector de odio](#4-entrenamiento-de-detector-de-odio)
  - [5. Aplicaci√≥n del modelo a los comentarios de reddit](#5-aplicaci√≥n-del-modelo-a-los-comentarios-de-reddit)
  - [6. An√°lisis de resultados](#6-an√°lisis-de-resultados)
  - [Conclusiones](#conclusiones)
  - [Trabajos futuros](#trabajos-futuros)
  - [Fuentes consultadas para el trabajo](#fuentes-consultadas-para-el-trabajo)
    - [Discursos de odio](#discursos-de-odio)
    - [reddit API](#reddit-api)
    - [Procesamiento de lenguaje natural](#procesamiento-de-lenguaje-natural)
    - [Clustering](#clustering)
    - [Trabajos relacionados](#trabajos-relacionados)



# Vistazo r√°pido

El presente repo contiene el c√≥digo correspondiente al proyecto final de la materia [Miner√≠a de datos para texto](https://sites.google.com/unc.edu.ar/textmining2021/), a cargo de Laura Alonso i Alemany.

Objetivo del proyecto: Caracterizar discursos de odio dentro de la comunidad de [reddit Argentina](https://reddit.com/r/argentina). Esto es, detectarlos y encontrar sub-lenguajes de odio en los mismos.

Para realizar esto, se llev√≥ a cabo un proceso consistente en 5 etapas, como se muestra en la siguiente figura:

![pipeline_reddit](/misc/workflow.drawio.png)


Cada etapa tiene su correspondiente notebook:

1. Obtenci√≥n del conjunto de comentarios de a trav√©s de la API de Reddit ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/1_pipeline_download_reddit_comments.ipynb)).
   
2. Pre-procesamiento del mismo ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/2_pipeline_preprocessing.ipynb)).

3. Aplicaci√≥n de embeddings y categorizaci√≥n en cl√∫sters (notebook [LDA](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3a_pipeline_lda.ipynb) [Word2Vec](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3b_pipeline_embedding_word2vec.ipynb) [FastText](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/3c_pipeline_embedding_fasttext.ipynb)).

4. Entrenamiento de un modelo de detecci√≥n de odio y extracci√≥n de palabras de odio en cada dataset ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/4_detect_hate_speech.ipynb)).
Para realizar el entrenamiento de los modelos, es necesario contar con los datasets respectivos de cada competencia (Hateval, DETOXIS, MeOffendMex) que se desee entrenar.

5. Uso del modelo para predecir los comentarios recolectados ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/5_pipeline_hate_speech.ipynb)).

6. Combinaci√≥n de dicho modelo con las categor√≠as encontradas para encontrar correlaciones ([notebook](https://github.com/PerseoSoft/redditHateSpeech/blob/main/src/6_pipeline_result.ipynb)).

**Este informe y proyecto estan en proceso üößüî®, todav√≠a sujetos a cambios, correcciones, y mejoras**

## Instalaci√≥n

### Instalaci√≥n con conda

Instalar Anaconda ([ver aqu√≠](https://docs.anaconda.com/anaconda/install/index.html)) y luego ejecutar:

```bash
#Crear entorno con conda y activarlo
conda env create -f environment.yml
conda activate hateSpeech
#Descarga del Trained pipelines de spaCy
python -m spacy download es_core_news_lg
#Correr Jupyter Lab
jupyter lab --ip=0.0.0.0 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''
```
Ir a [http://localhost:8888](http://localhost:8888) para acceder a la UI de Jupyter.

### Instalaci√≥n con Docker Compose

Instalar Docker Compose ([ver aqu√≠](https://docs.docker.com/compose/install/)) y luego ejecutar:

```bash
#Construir imagen
docker-compose build
#Correr Jupyter Lab
docker-compose up -d
```

Ir a [http://localhost:8888](http://localhost:8888) para acceder a la UI de Jupyter.

## Flujo de datos generados

Los distintos notebooks forman un pipeline en el cu√°l cada uno utiliza los datos generados por el anterior. Se listan cada una de las entradas:

1. Obtenci√≥n de comentarios. 
    - Archivos de entrada: N/A. 
    - Archivo de salida: *docs/reddit_data.csv*: CSV que contiene los comentarios de reddit descargados

2. Pre-procesamiento del dataset.
    - Archivos de entrada: *docs/reddit_data.csv*.
    - Archivos de salida: *docs/preprocessing_reddit_data.csv*: CSV con los comentarios pre-procesados.
   

3. Embeddings y clustering.
    - Archivos de entrada: *docs/preprocessing_reddit_data.csv*.
    - Archivos de salida: 
      - *docs/reddit_data_METODO.csv*, donde *METODO* puede ser 'lda', o 'word2vec', 'fasttext'. Cada uno de estos archivos toma el dataset pre-procesado y le agrega el n√∫mero de cl√∫ster al que pertenecer√≠a cada comentario, seg√∫n su cercan√≠a.
      - *docs/models/MODEL.model*, el modelo entrenado. Puede ser 'word2vec', o 'fasttext'. 
      - *docs/models/MODEL_kmeans.model*, el modelo de k-means entrenado usando los embeddings de *MODEL* (para 'word2vec' y 'fasttext').

    
4. Entrenamiento y selecci√≥n del modelo.
   - Archivos de entrada: *docs/hateval2019/hateval2019_es_train.csv*, *docs/detoxis_data/train.csv*, y *docs/MeOffendEs/mx-train-data-non-contextual.csv*. Estos archivos requieren la descarga previa manual de cada dataset.
   - Archivos de salida: para cada dataset, se guarda:
     - Palabras de odio de cada modelo: *docs/palabras_odio.csv*.
     - Vectorizador: *docs/models/DATASET_vectorizer.pkl* donde *DATASET* es hateval, detoxis, o meoffendmex.
     - Modelo entrenado: *docs/models/DATASET_INICIALES_MODELO_model.pkl* donde *INICIALES_MODELO* es 'lr', 'rf', o 'nb'.
   - Archivos de salida (de prueba): Predicciones: *docs/test/reddit_DATASET_hate_comments.csv*, uno para cada *DATASET*: 'hateval', 'detoxis', 'meoffendmex'.
   
5. Aplicaci√≥n del modelo en comentarios de reddit. 
   - Archivos de entrada: *docs/reddit_data_METODO.csv*.
   - Archivos de salida:
     - *docs/reddit_data_hate_speech.csv* - CSV que toma  **TODO**
6. An√°lisis de resultados.
   - Archivos de entrada: *docs/reddit_data_hate_speech.csv*
   - Archivos de salida: N/A.


# Informe del proyecto

Se muestra a continuaci√≥n el informe del proyecto, en donde se especifican la motivaci√≥n y objetivos del trabajo, y los distintos enfoques abordados para realizar la detecci√≥n de odio.

## Introducci√≥n

### Motivaci√≥n

El presente trabajo se enfoca en la detecci√≥n de discursos de odio en la comunidad seleccionada. Los objetivos del mismo son: **1)** detecci√≥n de comentarios con discurso de odio, y **2)** caracterizar ese discurso de odio en sub-lenguajes de odio.

El presente trabajo se basa en la siguiente hip√≥tesis: "en una comunidad en donde existen comentarios con discurso de odio, es posible combinar t√©cnicas de aprendizaje supervisado y no supervisado, para realizar la detecci√≥n de discursos de odio a partir de modelos que se especialicen en distintos grupos de comentarios".


### Discurso de odio

Hay varias posturas sobre lo que es discurso de odio, en general se coincide en que es un discurso que:

1. Apunta a un grupo o individuo, basado en alg√∫n aspecto como su orientaci√≥n sexual, religi√≥n, nacionalidad, etc.
2. Busca humillar, discriminar o propagar el odio/hostilidad hacia ese grupo.
3. Tiene una intenci√≥n deliberada.


Su manifestaci√≥n en Internet, adem√°s:

1. Puede motivar formas de agresi√≥n en l√≠nea.
2. Permite propagar el discurso de odio con velocidad.
3. Permite que el discurso se mantenga y comparta con facilidad.
4. Facilita la generaci√≥n de c√°maras de eco.
5. Al estar en servidores privados, permite que ciertas empresas intenten eludir su control, y usarlos para mantener sus usuarios interactuando con el servicio.

### r/argentina

[Reddit](https://www.reddit.com/) es una red social de ‚Äúcomunidades‚Äù creadas por usuarios. En este proyecto, nos centramos en [r/argentina](https://www.reddit.com/r/argentina/).

#### ¬øPor qu√© r/argentina?

Quisimos hacer nuestro trabajo enfocado en una comunidad Argentina fuera de las redes sociales m√°s comunes (dado que son aquellas m√°s com√∫nmente abordadas), pero que a la vez tenga el tama√±o suficiente como para tener muchos usuarios e interacciones. En ese sentido, r/argentina fue la opci√≥n m√°s prominente, ya que la comunidad es muy activa y cuenta con cerca de 350.000 subscriptores (a Noviembre de 2021).

#### Estructura general de un post

En la siguiente imagen podemos ver la estructura general de un post en reddit:

![](misc/reddit.png)

En cada comunidad sus miembros hacen posts, y cada post puede ser comentado generando debate. Su aspecto distintivo es que cada post o comentario recibe votos, con el objetivo de que aquellos posts o comentarios que m√°s aportan aparezcan encima de los que no. Tambi√©n se pueden premiar a aquellos destacados.

## 1. Obtenci√≥n de datos

[Notebook](/src/1_pipeline_download_reddit_comments.ipynb)

Para la obtenci√≥n de los datos se utiliz√≥ un *wrapper* de la API de reddit, llamado [praw](https://praw.readthedocs.io/en/stable/index.html), a partir del cu√°l descargamos comentarios de diferentes *post* del *subreddit* argentina, as√≠ como las respuestas de los comentarios.
Los comentarios en reddit pueden ser *link* o pueden ser solo textos. Filtramos solamente los comentarios que tengan textos. A la vez solo se consideraron comentarios que tuvieran como m√≠nimo cierta cantidad de caracteres.

De cada comentario que se guard√≥ de reddit, se obtuvieron los siguientes datos:
- *id*: identificador del *post* o comentario. Se guard√≥ por cuestiones de trazabilidad.
- *comment_parent_id*: identificador del comentario al cu√°l responde el comentario actual, en caso que corresponda. Se guard√≥ por cuestiones de trazabilidad.
- *flair*: categor√≠a del post, asignada por el usuario que lo crea (a partir de una lista brindada por el propio subreddit). En el caso de r/argentina, las categor√≠as incluyen t√≥picos como "Pol√≠tica", "Econom√≠a", "Humor", "Historia" o "Serio".
- *comms_num*: n√∫mero de respuestas que recibi√≥ el comentario.
- *score*: es un puntaje que los usuarios le dieron al comentario.

## 2. Pre-procesamiento

[Notebook](/src/2_pipeline_preprocessing.ipynb)

El pre-procesamiento consisti√≥ en:

- Eliminar emojis, urls, comillas, caracteres especiales, puntuaciones.
- Aplicar tokenizaci√≥n: en cada comentario, el token era la palabra.
- Conversi√≥n a min√∫scula.
- Eliminaci√≥n de stopwords utilizando spaCy.
- Lematizaci√≥n utilizando spaCy.
- Construir bigramas y trigramas.

## 3. Embeddings

Para poder detectar las subcomunidades dentro de reddit, comenzamos utilizando [Latent Dirichlet Allocation](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation): un m√©todo generativo muy utilizado, en el que se asume que cada documento est√° compuesto por una mezcla de t√≥picos, y donde cada palabra se relaciona con uno de ellos.

La elecci√≥n inicial de este modelo se bas√≥ en la diversidad de t√≥picos que el mismo es capaz de detectar.

Al aplicar este modelo, hemos observado que esta **TODO**.


Sin embargo, los resultados que obtuvimos no fueron satisfactorios, ya que a la hora de realizar un an√°lisis de los t√≥picos identificados por el modelo, encontramos poca cohesi√≥n entre los temas.

A ra√≠z de esto, probamos con *word embeddings* donde obtuvimos resultados que captan mucho mejor la sem√°ntica de la informaci√≥n. El proceso que llevamos a cabo en word embeddings para obtener las subcomunidades fue:

1. Generar una representaci√≥n vectorial de los comentarios: se mapearon los comentarios a partir de palabras en vectores num√©ricos.
2. Aplicamos un algoritmo de *clustering*, particularmente *k-means*, donde las caracter√≠sticas que se pasaron son los vectores num√©ricos obtenidos en el paso anterior.

Utilizamos dos t√©cnicas de word embeddings: [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) y [FastText](https://en.wikipedia.org/wiki/FastText).

A continuaci√≥n, mostramos algunos comentarios que fueron agrupados a trav√©s de las diferentes t√©cnicas aplicadas. Un evento particular que sucedi√≥ durante la descarga de estos datos en reddit fue el debate de la "[Ley de Promoci√≥n de la Alimentaci√≥n Saludable](https://www.boletinoficial.gob.ar/detalleAviso/primera/252728/20211112)", tambi√©n conocida como "ley de etiquetado frontal". Vamos a comparar las subcomunidades obtenidos en cada t√©cnica, analizando particularmente la aquellas referidas a este evento.


### 3a. Embeddings con LDA

[Notebook](/src/3a_pipeline_lda.ipynb)

En la siguiente imagen se pueden observar algunos de los t√≥picos identificados por LDA.

![](misc/embedding_1.png)

El t√≥pico n√∫mero 91, **piedra - etiqueta - pan - mira**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con la comida en general. Algunos comentarios son:

1. "Me alegro mucho, seguro muy feliz todos por el reencuentro. Igual te recomiendo que no coma directo de la lata, pasale a un platito o comedero. Entiendo que a veces ni te dan tiempo."
2. "Todo mi secundario el desayuno fue un fantoche triple y una lata de coca.  Y s√≥lo gastaba 2. Qu√© buenos tiempos.""
3. "La manteca no hace mal. Es muy dif√≠cil comer exceso de grasas para tu cuerpo en comparaci√≥n con lo f√°cil que es atiborrarte con az√∫car y carbohidratos. Esos son los verdaderos enemigos"
4. "Y con etiquetas que te dicen cu√°nta grasa tiene un kilo de bayonesa"
5. "Alta banfest se van a mandar los mods con este thread. Despedite de tu cuenta, maquinola, denunciado"


### 3b. Embeddings con Word2Vec

[Notebook](/src/3b_pipeline_embedding_word2vec.ipynb)

En la siguiente imagen se pueden observar algunas de las subcomunidades identificadas por Word2Vec.

![](misc/embedding_2.png)

El *cluster* n√∫mero 94, **ley - etiquetado - proyecto**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con las leyes en general. Algunos comentarios son:

1. "Una prueba mas de la ley de oferta y demanda"
2. "Con la nueva ley no le pod√©s regalar leche entera o un alfajor a un comedor, decir comida basura en un pa√≠s donde el 50\% de los chicos no hacen toda las comidas es lo m√°s clasista que existe."
3. "Recuerden la ley de alquileres.... Fu√© sancionada con un beso muy fuerte de los K, PRO y dem√°s muchachos..."
4. "No entiendo c√≥mo hay tanta gente en contra de una ley que no te cambia un carajo tu vida. Es la ley m√°s anodina que sac√≥ el Kirchnerismo en toda su historia creo"
5. "Pero hay leyes contra la violencia de genero! Como paso esto!!!1!?"
6. "No existe tal cosa en Argentina. Existe el Estado de Sitio, pero no se asemeja para nada a una ley marcial.. El concepto de ley marcial como tal, desapareci√≥ en el 94 con la nueva Constituci√≥n."


### 3c. Embeddings con FastText

[Notebook](/src/3c_pipeline_embedding_fasttext.ipynb)

En la siguiente imagen se pueden observar algunas de las subcominidades identificados por FastText.

![](misc/embedding_3.png)

Como se puede ver en el cluster **jaja - jajaja - jajajar - jajajaja - jajaj**, FastText identifica mejor las alteraciones que pueden suceder dentro de una palabra.

El *cluster* n√∫mero 113, **ley - etiquetado - votar**, incluye comentarios sobre la tratativa de la ley de etiquetado y temas que tienen que ver con las leyes en general. Algunos comentarios son:

1. "Feriado con fines tur√≠sticos. Ley 27.399"
2. "ajajaja como los cagaron a los primeros. como siempre la ley aplica a todos por igual /s"
3. "El sticker en Chile fue durante la transici√≥n de la ley. Imag√≠nate tener productos fabricados y tener que cambiar la envoltura a todos para que cumplan la ley"
4. "Gracias gloriosa ley de regulaci√≥n de alimentos, ahora se que desayunar coca cola con surtidos bagleys esta mal"
5. "Eso y que la ley va a prohibir vender dulces y gaseosas en los colegios, y usar im√°genes de famosos en los envases."
6. "Eso est√° por la ley Micaela no?. Tipo esta clase de capacitaciones no?"
7. "y ahora Lipovetzky reconoce lo de la ley de alquileres"


## 4. Entrenamiento de detector de odio

[Notebook](/src/4_detect_hate_speech.ipynb)

En paralelo a la b√∫squeda de cl√∫sters que agrupen los distintos t√≥picos, se busc√≥ tambi√©n, a partir de los datos [pre-procesados anteriormente](#2-pre-procesamiento) el detectar autom√°ticamente comentarios de odio, para poder combinarlos con los [t√≥picos encontrados](#3-embeddings). Para ello, se recurri√≥ a conjuntos de datos anotados y en castellano, que hayan utilizados para tareas similares. En particular, se opt√≥ por los siguientes tres:

**TODO poner las etiquetas que se decidieron usar en cada dataset**

1. HatEval: dataset con cerca de 7000 tweets de usuarios de Espa√±a, que potencialmente manifiestan discurso de odio contra mujeres o inmigrantes.
2. DETOXIS: dataset con cerca de 3500 comentarios de sitios de noticias/foros espa√±oles, que posiblemente contienen toxicidad.
3. MeOffendMex: dataset con alrededor de 5000 tweets de usuarios de M√©xico, que posiblemente contienen mensajes ofensivos.

En cada uno de los mismos, se entrenaron tres modelos de aprendizaje supervisado: *[regresi√≥n log√≠stica](https://en.wikipedia.org/wiki/Logistic_regression)*, *[naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)* y *[random forest](https://en.wikipedia.org/wiki/Random_forests)*, todos provistos por la librer√≠a [scikit-learn](https://scikit-learn.org).

Para realizar el entrenamiento, a cada comentario se le aplic√≥ el vectorizador [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), que transform√≥ cada comentario en una matriz *sparse* de forma

**TODO**

$$$$

Tal matriz, junto con las correspondientes etiquetas de cada comentario, constituyeron la entrada de cada uno de los modelos. Tales modelos funcionaron bastante bien con sus configuraciones b√°sicas, **TODO**, mostrando matrices de confusi√≥n s√≥lidas. Especialmente, los que mejor performaron fueron naive Bayes y random forest.

Una vez entrenados, se extrajeron las palabras de odio de naive Bayes y random forest, de acuerdo al criterio **TODO**.

La salida del detector de odio se puede ver en el archivo **TODO**.


## 5. Aplicaci√≥n del modelo a los comentarios de reddit

[Notebook](/src/5_pipeline_hate_speech.ipynb)

Una vez teniendo los modelos entrenados, el siguiente paso fue aplicarlos en .



## 6. An√°lisis de resultados

[Notebook](/src/6_pipeline_result.ipynb)


## Conclusiones


## Trabajos futuros


## Fuentes consultadas para el trabajo

### Discursos de odio

- https://en.wikipedia.org/wiki/Hate_speech
- https://www.rightsforpeace.org/hate-speech
- https://fsi.stanford.edu/news/reddit-hate-speech
- https://variety.com/2020/digital/news/reddit-bans-hate-speech-groups-removes-2000-subreddits-donald-trump-1234692898
- https://www.reddithelp.com/hc/en-us/articles/360045715951-Promoting-Hate-Based-on-Identity-or-Vulnerability

### reddit API

- https://www.jcchouinard.com/reddit-api/


### Procesamiento de lenguaje natural

- Foundations of Statistical Natural Language Processing - Manning & Sch√ºtze (1999)
- https://spacy.io
- https://radimrehurek.com/gensim/
- https://www.nltk.org
- https://www.baeldung.com/cs/ml-word2vec-topic-modeling
- https://www.kdnuggets.com/2018/04/robust-word2vec-models-gensim.html
- https://adrian-rdz.github.io/NLP_word2vec/
- https://towardsdatascience.com/applying-machine-learning-to-classify-an-unsupervised-text-document-e7bb6265f52
- https://dylancastillo.co/nlp-snippets-cluster-documents-using-word2vec/
- https://www.roelpeters.be/calculating-mutual-information-in-python/

### Clustering

- https://towardsdatascience.com/k-means-clustering-8e1e64c1561c
- https://paperperweek.wordpress.com/2018/04/09/best-ways-to-cluster-word2vec/
- https://ai.intelligentonlinetools.com/ml/k-means-clustering-example-word2vec/
- https://medium.com/@rohithramesh1991/unsupervised-text-clustering-using-natural-language-processing-nlp-1a8bc18b048d
- https://xplordat.com/2018/12/14/want-to-cluster-text-try-custom-word-embeddings/
- https://towardsdatascience.com/clustering-with-more-than-two-features-try-this-to-explain-your-findings-b053007d680a

### Trabajos relacionados

- https://github.com/jfreddypuentes/spanlp
- https://medium.com/ml2vec/using-word2vec-to-analyze-reddit-comments-28945d8cee57
- https://www.kaggle.com/szymonjanowski/internet-articles-data-with-users-engagement
- https://towardsdatascience.com/religion-on-twitter-5f7b84062304
- https://becominghuman.ai/detecting-gender-based-hate-speech-in-spanish-with-natural-language-processing-cdbba6ec2f8b
- https://www.learndatasci.com/tutorials/sentiment-analysis-reddit-headlines-pythons-nltk/
